<!DOCTYPE html>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
  <title>Arroyo Case Study</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <link rel="icon" href="./images/logos/color/arroyographic_color.svg" />
  <link rel="stylesheet" href="assets/css/main.css" />
  <noscript>
    <link rel="stylesheet" href="assets/css/noscript.css" />
  </noscript>
</head>

<body class="is-preload">
  <!-- Header -->
  <header id="header">
    <nav>
      <ul>
        <li><a href="index.html" class="fa fa-home fa-3x" id="home-icon" ></a></li>
        <li>
          <a id="github-icon" href="https://github.com/Team-Arroyo/arroyo" class="icon brands fa-github fa-3x"
            target="_blank"></a>
        </li>
      </ul>
    </nav>
  </header>

  <!-- Wrapper -->
  <div id="wrapper">
    <!-- Main -->
    <section id="case-study" class="wrapper style1">
      <div class="inner">
        <h1 class="major">Case Study</h1>
        <h2 id="section-1" class="section-heading">1. Introduction</h2>
        <p>As systems become increasingly complex, it becomes more important - and simultaneously more difficult - to understand what is going on within them. The ability to monitor such systems and efficiently access specific information about them is vital.</p>
        <h3>Arroyo</h3>
        <p>An arroyo is a creek bed or gulch that temporarily fills with water after sufficient rain.</p>
        <figure><img class="medium case-study-image" src="images/case-study/dry_creek.jpg" /></figure>
        <p>Arroyo is a lightweight framework that granularly rehydrates logs kept in cloud storage.</p>
        <h3>Memely</h3>
        <p>To help illustrate what Arroyo is and why it is useful, let’s meet Memely.</p>
        <p>Memely is a small image and video hosting service that strives to provide a “one-stop shop for non-stop laughs” by consolidating the most popular content being shared across the web into one place.</p>
        <figure><img class="small case-study-image" src="images/case-study/memely_intro.png" /></figure>
        <p>Memely.com was not an overnight sensation, but over time their user base has grown considerably, exceeding even their most ambitious predictions. This growth enabled the Memely team to start generating pay-per-click ad revenue by hosting ads on their front page. With time, these profits became consistent and substantial enough that Memely was able to reinvest in their site by hiring a small team of full-time developers.</p>
        <p>The engineering team’s first priority was to scale the Memely architecture to accommodate their growing user base. During the initial phase of infrastructural scaling, the complexity of Memely’s system increased considerably, and it quickly became clear that the current system did not contain the level of observability required to continue scaling confidently.</p>
        <p>To complicate matters further, some troubling user behavior has necessitated an audit. The ad agency which Memely’s site hosts ads from is concerned about possible “click fraud”.</p>
        <figure><img class="small case-study-image" src="images/case-study/click_graph.gif" /></figure>
        <p>Over the past month the number of clicks, or “user engagements”, with the ads the agency generates and that memely.com hosts were far higher than usual. The agency has asked that the Memely team investigate: no small feat in Memely’s increasingly complex infrastructure.</p>
        <h2 id="section-2" class="section-heading">2. Observability</h2>
        <figure><img class="xs case-study-image" src="images/case-study/observability.png"/></figure>
        <figcaption>“To observe is to watch carefully.”</figcaption>
        <p>Observability is the ability to measure the current state of a system using the data the system outputs. Instrumentation is adding code to output that data. The collection of these instrument measurements is called telemetry.</p>
        <h3>The Pillars of Observability</h3>
        <p>Observability is often said to be composed of three “pillars”: metrics, traces, and logs.</p>
        <h4>Metrics</h4>
        <p>Metrics provide numeric information about the state of a service at runtime. Typically, metrics are aggregations of data over a period of time.</p>
        <p>The most commonly used metrics are availability, request rate, utilization, and latency. Availability represents the number of requests to a service that result in errors; request rate is a measure of requests per second; utilization is a numerical expression of a system’s CPU or memory usage; and latency is a measure of a system’s response time. These key metrics are often referred to as the ‘Four Golden Signals’.</p>
        <h4>Traces</h4>
        <p>Traces record the paths taken by individual requests through a distributed system over time. Each trace is built from multiple spans, which represent time intervals during which discrete operations occur: an API call, or a database write operation. Typically traces are represented by showing a collection of spans organized by time in a waterfall diagram or a flame graph.</p>
        <figure><img class="medium case-study-image" src="images/case-study/flame_graph.png" /></figure>
        <figcaption>An example flame graph</figcaption>
        <h4>Logs</h4>
        <figure><img class="medium case-study-image" src="images/case-study/structured_logs.png" /></figure>
        <figcaption>A log file in JSON format</figcaption>
        <p>Logs are text records of events, and ideally include a timestamp. They come in various structured formats including JSON, CSV, and Common Event Format (CEF), but logs can be completely unstructured as well. Logs provide the most detailed view of what is going on within an application or service.</p>
        <p>As a system grows, the number of metrics stays constant due to the aggregate nature of metrics. Traces increase linearly with the amount of requests; the complexity of the system does not impact the amount of traces. However, for the same increase in system complexity, the amount of logs increases faster than the number of traces or metrics.</p>
        <h4>Scaling Logs</h4>
        <p>Although logs are useful for gaining insight into a system, they don’t scale well. This is particularly evident in distributed systems.</p>
        <p>Every component of a system’s architecture is likely to produce logs. When services are added to an infrastructure, those nodes will also produce more logs, which by default are stored locally. When logs are stored locally, users must first correctly identify the node containing the desired log entries. As the number of nodes increases, it rapidly becomes infeasible to identify the correct node manually.</p>
        <p>Therefore, to find the information needed within a distributed system or with a large volume of logs, it is necessary to gather the logs into a centralized location to more efficiently perform searches and analysis there. One popular log management system is called the ELK stack, which is an acronym for the three tools it is composed of: Elasticsearch, Logstash, and Kibana.</p>
        <h3>ELK Stack</h3>
        <figure><img class="medium case-study-image" src="images/case-study/elk_overview.png"/></figure>
        <figcaption>An overview of the ELK stack</figcaption>
        <h4>Logstash</h4>
        <figure><img class="xxs case-study-image" src="images/case-study/logstash_logo.png"/></figure>
        <p>Logstash is a plugin-based data processing pipeline. Its functionality can be broken into three phases: input, transformation, and output. In the case of log management, Logstash takes in the text files where logs are stored (input phase); transforms these text files into a format that is more conducive to searching, like JSON (transformation phase); and sends the transformed data elsewhere for storage (output phase) In an ELK stack, the transformed data is sent to Elasticsearch.</p>
        <figure><img class="medium case-study-image" src="images/case-study/logstash_stages.png" /></figure>
        <h4>Elasticsearch</h4>
        <figure><img class="xxs case-study-image" src="images/case-study/elasticsearch_logo.png"/></figure>
        <p>Elasticsearch is a flexible tool that can serve as a distributed document store, a real-time search engine, and an analytics engine.</p>
        <p>Elasticsearch can be described as “real-time” because it can index incoming  data  to make the data searchable in one second. An index in Elasticsearch is like a database in a relational database management system(RDBMS). However, in contrast to a relational database, it is easy to search multiple indexes; therefore, when using Elasticsearch for logs, each day is usually given its own index.</p>
        <p>To search indexed data, users can write queries with either a domain specific language for searching JSON files, with SQL, or with Event Query Language (EQL).  Also, searches can be run on aggregate data such as metrics. Once indexed, searchable logs are kept in Elasticsearch.</p>
        <p>However, the more data stored in Elasticsearch, the slower searching will be. To keep searching performant , the amount of data kept in Elasticsearch must be minimized . One way of managing the data contained in Elasticsearch is by using an index lifecycle policy, which enables a high degree of control over how long an index will be retained. For example, an index may be deleted once it has been stored in Elasticsearch for a certain amount of time.</p>
        <figure><img class="xs case-study-image" src="images/case-study/ilm.gif"/></figure>
        <p>While searching for information can be performed via the Elasticsearch API, the search results will be presented as a JSON document. For information-rich data, such as logs, it is beneficial to visualize the data in order to understand the state of a system at a glance and make informed decisions. JSON may not succinctly summarize the results in a visually impactful format which is why the ELK stack includes a visualization tool called Kibana.</p>
        <h4>Kibana</h4>
        <figure><img class="xxs case-study-image" src="images/case-study/kibana_graphic.png"/></figure>
        <p>Kibana is a  graphical user interface that lets users visualize their data by allowing them to flexibly query Elasticsearch, to create graphs, and to build custom dashboards. Visualizing information-rich data, such as logs, allows users to see what is happening within their system at a glance.</p>
        <p>In addition, Kibana allows users to manage their Elasticsearch cluster in a more intuitive environment by allowing users to perform administrative tasks like creating index lifecycle policies in the Kibana dashboard. Otherwise, users would need to manage Elasticsearch via its API.</p>
        <p>The ELK stack allows users to aggregate and analyze logs, and to create visualizations for application and infrastructure monitoring. Using the ELK stack for log management is a great step towards achieving an observable system, especially if it’s combined with a system for managing traces and metrics. With the three pillars of observability in mind, let’s return to Memely to see how they use their ELK Stack to collect, search, and analyze their logs.</p>
        <h2 id="section-3" class="section-heading">3. Log Rehydration</h2>
        <h3>Memely’s ELK Stack</h3>
        <p>After implementing an ELK stack of their own, the Memely team can search all of the logs generated by the Memely infrastructure, which has allowed them to derive metrics based on the data the logs contain. For example, the team can visualize their web server logs and analyze server response times to gauge how memely.com’s growing user base has impacted the site’s availability.  With the added oversight that an ELK stack provides, the Memely team feels more confident about their current scaling efforts.</p>
        <p>However, utilizing an ELK stack has introduced a separate set of challenges for the Memely team. Elasticsearch's strength is fast searching, but the search speed slows as the number of documents increases. Additionally, increasing the number of documents introduces complexity concerning index management and memory allocation within Elasticsearch.</p>
        <p>To address these challenges, the Memely team decides to store their logs in two locations. First, Memely will ship their logs to AWS S3 for archival. Second, to keep Elasticsearch manageable and performant, Memely will index only the most recent 14 days' worth of logs into Elasticsearch. This solution reduces the number of documents stored in Elasticsearch and grants the Memely team peace of mind knowing all their logs are archived in secure cloud storage.</p>
        <figure><img class="small case-study-image" src="images/case-study/memely_dual_logs.gif" /></figure>
        <figcaption>Memely using Logstash to ship logs to AWS S3 and Elasticsearch</figcaption>
        <h3>The Audit</h3>
        <h4>Suspicious Client IP</h4>
        <p>When we last left Memely, the ad agency that memely.com hosts ads from had requested that Memely investigate a suspiciously high number of user engagements that indicated an event of “click fraud”. Thanks to their new ELK Stack, Memely team was quickly able to gather information about the requests made to memely.com over the previous two weeks. Memely’s ELK Stack played an invaluable role here, and the team was quickly able to establish that one client IP address was responsible for a drastically disproportionate number of the requests made in the previous 14 days.</p>
        <figure><img class="small case-study-image" src="images/case-study/ip_dist_donut.png" /></figure>
        <h4>Suspicious Behavior</h4>
        <p>In order to better understand how this client had been interacting with their site, the Memely team looked at all of the indexed web server logs involving the client’s IP address. They discovered that all of the requests issued by the client had been GET requests sent to the root page of memely.com, where the majority of the hosted ads are served. They also observed that the client made no attempts to visit any other pages within the site, which deviates from the way that most users interact with their site. At this point the Memely team is confident that they are dealing with a malicious user, reinforcing suspicions that memely.com experienced click fraud within the past 30 days.</p>
        <figure><img class="small case-study-image" src="images/case-study/behavior_breakdown.png" /></figure>
        <p>The next thing the Memely team would like to know is how long this has been going on. Because they only have the most recent 14 days of logs indexed in Elasticsearch, the Memely team does not currently have all of the data that they need in order to complete their audit.</p>
        <h4>Log Rehydration</h4>
        <p>What the Memely team needs is a way to transfer logs they currently have archived in AWS S3 back into Elasticsearch so that they can search them within an environment that is feature-rich and familiar. This process of transferring archived logs back into Elasticsearch for easier searching is often referred to as log rehydration and the Memely team has a few options at their disposal.</p>






      </div>  
    </section>
  </div>

  <!-- TOC -->
  <aside id="toc" class="">
    <ul>
      <!-- Section 1 -->
      <li data-section="section-1" class="selected">
        <a href="#section-1">
          <div>
            <div class="bullet">
              <div></div>
            </div>
            <p>Introduction</p>
          </div>
        </a>
      </li>
      <!-- Section 2 -->
      <li data-section="section-2">
        <a href="#section-2">
          <div>
            <div class="bullet">
              <div></div>
            </div>
            <p>Observability</p>
          </div>
        </a>
      </li>
          <!-- Section 3 -->
      <li data-section="section-3" >
        <a href="#section-3">
          <div>
            <div class="bullet">
              <div></div>
            </div>
            <p>Log Rehydration</p>
          </div>
        </a>
      </li>
      
      <!-- Section 4 -->
      <li data-section="section-4">
        <a href="#section-4">
          <div>
            <div class="bullet">
              <div></div>
            </div>
            <p>Existing Solutions</p>
          </div>
        </a>
      </li>
      <!-- Section 5 -->
      <li data-section="section-5" >
        <a href="#section-5">
          <div>
            <div class="bullet">
              <div></div>
            </div>
            <p>Arroyo</p>
          </div>
        </a>
      </li>
      <!-- Section 6 -->
      <li data-section="section-6" >
        <a href="#section-6">
          <div>
            <div class="bullet">
              <div></div>
            </div>
            <p>Using Arroyo</p>
          </div>
        </a>
      </li>
      <!-- Section 7 -->
      <li data-section="section-7" >
        <a href="#section-7">
          <div>
            <div class="bullet">
              <div></div>
            </div>
            <p>Arroyo Architecture</p>
          </div>
        </a>
      </li>
      
      <!-- Section 8 -->
      <li data-section="section-8" >
        <a href="#section-8">
          <div>
            <div class="bullet">
              <div></div>
            </div>
            <p>Engineering Decisions</p>
          </div>
        </a>
      </li>
      
      <!-- Section 9 -->
      <li data-section="section-9" >
        <a href="#section-9">
          <div>
            <div class="bullet">
              <div></div>
            </div>
            <p>Future Work</p>
          </div>
        </a>
      </li>
      <!-- Section 10 -->
      <li data-section="section-10" >
        <a href="#section-10">
          <div>
            <div class="bullet">
              <div></div>
            </div>
            <p>References</p>
          </div>
        </a>
      </li>
    </ul>
  </aside>

  <!-- Footer -->
  <footer id="footer" class="wrapper style1">
    <div class="inner" id="case-study-footer-list">
      <ul class="menu">
        <li >
          <a href="#header" class="fa fa-arrow-up fa-3x case-study-footer-icon"></a>
        </li>
        <li>
          <a href="index.html" class="fa fa-home fa-3x case-study-footer-icon" ></a>
        </li>
        <li>
          <p style="color: lightgray;">&copy; 2022 Arroyo. All rights reserved.<br>Design: <a href="http://html5up.net">HTML5 UP</a></p>
        </li>
        
      </ul>
    </div>
  </footer>

  <!-- Scripts -->
  <script src="assets/js/jquery.min.js"></script>
  <script src="assets/js/jquery.scrollex.min.js"></script>
  <script src="assets/js/jquery.scrolly.min.js"></script>
  <script src="assets/js/browser.min.js"></script>
  <script src="assets/js/breakpoints.min.js"></script>
  <script src="assets/js/util.js"></script>
  <script src="assets/js/main.js"></script>
  <script src="assets/js/script.js"></script>
</body>

</html>
